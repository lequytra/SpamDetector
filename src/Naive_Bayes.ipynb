{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\n",
    "import itertools\n",
    "from eval_utils import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), '../Data/spam.csv'), 'r',  encoding='latin-1') as f:\n",
    "    data = pd.read_csv(f)\n",
    "data.drop(labels=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain labels for data: {'ham': 0, 'spam': 1}\n",
    "labels = data['v1'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8404)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encode the email to sparse matrices\n",
    "f = feature_extraction.text.CountVectorizer(stop_words = 'english')\n",
    "X = f.fit_transform(data[\"v2\"])\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for training: (3733, 8404)\n",
      "Data shape for testing: (1839, 8404)\n"
     ]
    }
   ],
   "source": [
    "# Split train-test set\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, labels, test_size=0.33, random_state=42)\n",
    "print(\"Data shape for training: {}\\nData shape for testing: {}\".format(np.shape(X_train), np.shape(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5569007263922519\t\t Recall: 0.9126984126984127\t\t F1 Score: 0.6917293233082707\t\t Accuracy: 0.88852637302882\n"
     ]
    }
   ],
   "source": [
    "spam_proba = len(y_train[y_train == 1])/len(y_train)\n",
    "#Create a Gaussian Classifier\n",
    "model = naive_bayes.GaussianNB()\n",
    "# Train the model using the training sets\n",
    "model.fit(X_train.toarray(),y_train)\n",
    "pred = model.predict(X_test.toarray())\n",
    "evaluate(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.90625\t\t Recall: 0.9206349206349206\t\t F1 Score: 0.9133858267716536\t\t Accuracy: 0.9760739532354541\n"
     ]
    }
   ],
   "source": [
    "modelM = naive_bayes.MultinomialNB()\n",
    "modelM.fit(X_train, y_train)\n",
    "predM = modelM.predict(X_test)\n",
    "evaluate(predM, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7109144542772862\t\t Recall: 0.9563492063492064\t\t F1 Score: 0.8155668358714044\t\t Accuracy: 0.9407286568787384\n"
     ]
    }
   ],
   "source": [
    "modelC = naive_bayes.ComplementNB()\n",
    "modelC.fit(X_train, y_train)\n",
    "predC = modelC.predict(X_test)\n",
    "evaluate(predC, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\t\t Recall: 0.876984126984127\t\t F1 Score: 0.9344608879492601\t\t Accuracy: 0.9831430125067971\n"
     ]
    }
   ],
   "source": [
    "modelS = svm.LinearSVC()\n",
    "modelS.fit(X_train, y_train)\n",
    "predS = modelS.predict(X_test)\n",
    "evaluate(predS, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = predS - y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res1[res1 != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
